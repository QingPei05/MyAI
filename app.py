import sys
import subprocess
import streamlit as st
from PIL import Image
import numpy as np
import cv2

# ======================
# ä¾èµ–è‡ªåŠ¨å®‰è£…ä¿éšœæ¨¡å—
# ======================
def install_and_import(package):
    """è‡ªåŠ¨å®‰è£…ç¼ºå¤±çš„ä¾èµ–åŒ…"""
    try:
        __import__(package.split('==')[0])
    except ImportError:
        st.warning(f"æ­£åœ¨å®‰è£…ä¾èµ–: {package}...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", package])
        st.success("ä¾èµ–å®‰è£…å®Œæˆï¼è¯·åˆ·æ–°é¡µé¢")
        st.experimental_rerun()

# ç¡®ä¿æ ¸å¿ƒä¾èµ–å­˜åœ¨
REQUIRED_PACKAGES = [
    "opencv-python-headless==4.9.0.80",
    "streamlit==1.32.0",
    "Pillow==10.2.0",
    "numpy==1.26.4"
]

for package in REQUIRED_PACKAGES:
    install_and_import(package)

# ======================
# åº”ç”¨ä¸»ç•Œé¢
# ======================
def main():
    st.set_page_config(
        page_title="é«˜ç²¾åº¦åœ°ç‚¹æƒ…ç»ªæ£€æµ‹ç³»ç»Ÿ",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    st.title("ğŸŒ é«˜ç²¾åº¦åœ°ç‚¹ä¸æƒ…ç»ªæ£€æµ‹")
    st.markdown("""
    <style>
    .stProgress > div > div > div > div {
        background-color: #1E90FF;
    }
    .st-emotion-cache-1kyxreq {
        display: flex;
        justify-content: center;
    }
    </style>
    """, unsafe_allow_html=True)

    # ======================
    # æ–‡ä»¶ä¸Šä¼ åŒºåŸŸ
    # ======================
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ å›¾ç‰‡æˆ–è§†é¢‘ (æ”¯æŒ JPG/PNG/MP4)", 
        type=["jpg", "jpeg", "png", "mp4"],
        help="å»ºè®®åŒ…å«æ¸…æ™°æ–‡å­—æˆ–åœ°æ ‡çš„åª’ä½“æ–‡ä»¶"
    )

    if uploaded_file is not None:
        if uploaded_file.type.startswith('image'):
            process_image(uploaded_file)
        elif uploaded_file.type.startswith('video'):
            process_video(uploaded_file)

# ======================
# å›¾ç‰‡å¤„ç†å‡½æ•°
# ======================
def process_image(uploaded_file):
    """å¤„ç†ä¸Šä¼ çš„å›¾ç‰‡"""
    try:
        image = Image.open(uploaded_file).convert('RGB')
        img_array = np.array(image)
        
        col1, col2 = st.columns(2)
        with col1:
            st.image(image, caption="ä¸Šä¼ çš„å›¾ç‰‡", use_column_width=True)
        
        with st.spinner('æ­£åœ¨åˆ†æ...'):
            # åœ°ç‚¹æ£€æµ‹
            location = detect_location(img_array)
            
            # æƒ…ç»ªæ£€æµ‹
            emotions = detect_emotions(img_array)
        
        with col2:
            display_results(location, emotions)
            
    except Exception as e:
        st.error(f"å¤„ç†å›¾ç‰‡æ—¶å‡ºé”™: {str(e)}")

# ======================
# è§†é¢‘å¤„ç†å‡½æ•°
# ======================
def process_video(uploaded_file):
    """å¤„ç†ä¸Šä¼ çš„è§†é¢‘"""
    try:
        st.warning("è§†é¢‘å¤„ç†å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
        
        # åˆ›å»ºä¸´æ—¶æ–‡ä»¶
        with st.spinner('å‡†å¤‡è§†é¢‘åˆ†æ...'):
            tfile = tempfile.NamedTemporaryFile(delete=False, suffix='.mp4')
            tfile.write(uploaded_file.read())
            video_path = tfile.name
        
        # åˆ†æè§†é¢‘
        with st.spinner('åˆ†æè§†é¢‘å¸§...'):
            results = analyze_video_frames(video_path)
            os.unlink(video_path)  # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
        
        st.success("åˆ†æå®Œæˆï¼")
        display_video_results(results)
        
    except Exception as e:
        st.error(f"å¤„ç†è§†é¢‘æ—¶å‡ºé”™: {str(e)}")

# ======================
# æ ¸å¿ƒæ£€æµ‹å‡½æ•° (éœ€å®ç°)
# ======================
def detect_location(image_array):
    """åœ°ç‚¹æ£€æµ‹é€»è¾‘"""
    # è¿™é‡Œåº”è¯¥è°ƒç”¨ä½ çš„åœ°ç‚¹æ£€æµ‹æ¨¡å—
    # ç¤ºä¾‹å®ç°ï¼š
    try:
        # ä½¿ç”¨OpenCVè¿›è¡Œç®€å•å¤„ç†
        gray = cv2.cvtColor(image_array, cv2.COLOR_RGB2GRAY)
        # è¿™é‡Œåº”è¯¥æ˜¯ä½ çš„å®é™…åœ°ç‚¹æ£€æµ‹ä»£ç 
        return "ç¤ºä¾‹åœ°ç‚¹: åŒ—äº¬å¤©å®‰é—¨"
    except:
        return "æ— æ³•è¯†åˆ«åœ°ç‚¹"

def detect_emotions(image_array):
    """æƒ…ç»ªæ£€æµ‹é€»è¾‘"""
    # è¿™é‡Œåº”è¯¥è°ƒç”¨ä½ çš„æƒ…ç»ªæ£€æµ‹æ¨¡å—
    # ç¤ºä¾‹å®ç°ï¼š
    try:
        # è¿™é‡Œåº”è¯¥æ˜¯ä½ çš„å®é™…æƒ…ç»ªæ£€æµ‹ä»£ç 
        return {"happy": 0.7, "neutral": 0.3}
    except:
        return {"error": "æƒ…ç»ªæ£€æµ‹å¤±è´¥"}

def analyze_video_frames(video_path):
    """åˆ†æè§†é¢‘å¸§"""
    # è¿™é‡Œåº”è¯¥è°ƒç”¨ä½ çš„è§†é¢‘å¤„ç†æ¨¡å—
    # ç¤ºä¾‹å®ç°ï¼š
    return [
        {"frame": 1, "location": "åœ°ç‚¹1", "emotions": {"happy": 0.8}},
        {"frame": 2, "location": "åœ°ç‚¹1", "emotions": {"happy": 0.7}}
    ]

# ======================
# ç»“æœæ˜¾ç¤ºå‡½æ•°
# ======================
def display_results(location, emotions):
    """æ˜¾ç¤ºåˆ†æç»“æœ"""
    st.subheader("åˆ†æç»“æœ")
    
    st.markdown("### ğŸ“ åœ°ç‚¹è¯†åˆ«")
    if location:
        st.success(location)
    else:
        st.warning("æ— æ³•è¯†åˆ«åœ°ç‚¹")
    
    st.markdown("### ğŸ˜Š æƒ…ç»ªåˆ†æ")
    if isinstance(emotions, dict):
        for emotion, score in emotions.items():
            st.progress(score, text=f"{emotion}: {score:.2f}")
    else:
        st.warning(emotions)

def display_video_results(results):
    """æ˜¾ç¤ºè§†é¢‘åˆ†æç»“æœ"""
    st.subheader("è§†é¢‘åˆ†ææŠ¥å‘Š")
    
    # æ˜¾ç¤ºæ•°æ®è¡¨æ ¼
    st.dataframe(
        pd.DataFrame(results),
        use_container_width=True,
        height=300
    )
    
    # æ˜¾ç¤ºæƒ…ç»ªå˜åŒ–å›¾è¡¨
    emotion_df = pd.DataFrame(results).explode('emotions')
    st.line_chart(
        emotion_df.groupby('frame')['emotions'].value_counts().unstack(),
        height=400
    )

# ======================
# ä¸»ç¨‹åºå…¥å£
# ======================
if __name__ == "__main__":
    # å¯¼å…¥é¢å¤–ä¾èµ–ï¼ˆä»…åœ¨éœ€è¦æ—¶ï¼‰
    try:
        import pandas as pd
        import tempfile
        import os
    except ImportError:
        st.warning("æ­£åœ¨å®‰è£…é¢å¤–ä¾èµ–...")
        subprocess.check_call([sys.executable, "-m", "pip", "install", "pandas"])
        st.experimental_rerun()
    
    main()
