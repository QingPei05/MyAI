import streamlit as st
import cv2
import numpy as np
from PIL import Image
from utils.location_utils import detect_location
from utils.emotion_utils import detect_emotions
from utils.video_processor import process_video
import tempfile
import os

# é¡µé¢é…ç½®
st.set_page_config(page_title="Geo-Emotion Analyzer", layout="wide")
st.title("ğŸŒ é«˜ç²¾åº¦åœ°ç‚¹ä¸æƒ…ç»ªæ£€æµ‹ç³»ç»Ÿ")
st.markdown("""
<style>
.stProgress > div > div > div > div {
    background-color: #1E90FF;
}
</style>
""", unsafe_allow_html=True)

# æ–‡ä»¶ä¸Šä¼ 
uploaded_file = st.file_uploader(
    "ä¸Šä¼ å›¾ç‰‡æˆ–è§†é¢‘ (æ”¯æŒ JPG/PNG/MP4)", 
    type=["jpg", "jpeg", "png", "mp4"],
    help="å»ºè®®åŒ…å«æ¸…æ™°æ–‡å­—æˆ–åœ°æ ‡çš„åª’ä½“æ–‡ä»¶"
)

if uploaded_file is not None:
    if uploaded_file.type.startswith('image'):
        # å¤„ç†å›¾ç‰‡
        image = Image.open(uploaded_file).convert('RGB')
        img_array = np.array(image)
        
        col1, col2 = st.columns(2)
        with col1:
            st.image(image, caption="åŸå§‹å›¾ç‰‡", use_column_width=True)
        
        with st.spinner('æ­£åœ¨åˆ†æ...'):
            # å¹¶è¡Œå¤„ç†
            with st.expander("é«˜çº§é€‰é¡¹", expanded=False):
                enable_google_api = st.checkbox("å¯ç”¨Google Vision API", True)
                enable_emotion = st.checkbox("å¯ç”¨æƒ…ç»ªæ£€æµ‹", True)
            
            location = detect_location(img_array, enable_google_api)
            if enable_emotion:
                emotions = detect_emotions(img_array)
        
        # æ˜¾ç¤ºç»“æœ
        with col2:
            st.subheader("åˆ†æç»“æœ")
            st.markdown(f"""
            ### ğŸ“ åœ°ç‚¹è¯†åˆ«
            **{location if location else "æœªè¯†åˆ«åˆ°æœ‰æ•ˆåœ°ç‚¹"}**
            
            ### ğŸ˜Š æƒ…ç»ªåˆ†æ
            {emotions if enable_emotion else "æœªå¯ç”¨æƒ…ç»ªæ£€æµ‹"}
            """)
            
    elif uploaded_file.type.startswith('video'):
        # å¤„ç†è§†é¢‘
        st.warning("è§†é¢‘å¤„ç†å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´ï¼Œè¯·è€å¿ƒç­‰å¾…...")
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmp:
            tmp.write(uploaded_file.read())
            video_path = tmp.name
        
        results = process_video(video_path)
        os.unlink(video_path)
        
        st.success("åˆ†æå®Œæˆï¼")
        st.dataframe(results, height=300)
        st.line_chart(results['emotions'].value_counts())
