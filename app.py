import cv2
import numpy as np
import streamlit as st
from PIL import Image, ImageDraw, ImageFont  # æ·»åŠ ç¼ºå¤±çš„å¯¼å…¥

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')

def detect_emotion(img):
    """ä½¿ç”¨OpenCVæ£€æµ‹æƒ…ç»ªï¼ˆå¿«ä¹ã€å¹³é™ã€æ‚²ä¼¤ã€æ„¤æ€’ï¼‰"""
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.3, 5)
    
    emotions = []
    for (x,y,w,h) in faces:
        roi_gray = gray[y:y+h, x:x+w]
        
        # æ£€æµ‹å¾®ç¬‘
        smiles = smile_cascade.detectMultiScale(roi_gray, scaleFactor=1.8, minNeighbors=20)
        # æ£€æµ‹çœ¼ç›
        eyes = eye_cascade.detectMultiScale(roi_gray)
        
        # æƒ…ç»ªåˆ¤æ–­é€»è¾‘
        emotion = "å¹³é™"  # é»˜è®¤
        
        # æ„¤æ€’åˆ¤æ–­
        if len(eyes) >= 2:
            eye_centers = [y + ey + eh/2 for (ex,ey,ew,eh) in eyes[:2]]
            avg_eye_height = np.mean(eye_centers)
            eye_sizes = [eh for (ex,ey,ew,eh) in eyes[:2]]
            avg_eye_size = np.mean(eye_sizes)
            
            if avg_eye_size > h/5 and avg_eye_height < h/2.5:
                emotion = "æ„¤æ€’"
            elif avg_eye_height < h/3:
                emotion = "æ‚²ä¼¤"
        
        # å¿«ä¹åˆ¤æ–­ï¼ˆä¼˜å…ˆåˆ¤æ–­ï¼‰
        if len(smiles) > 0:
            emotion = "å¿«ä¹"
        
        emotions.append(emotion)
    
    return emotions, faces

def draw_detections(img, emotions, faces):
    """ç¡®ä¿ä¸­æ–‡æ ‡ç­¾æ­£ç¡®æ˜¾ç¤ºçš„ç»˜åˆ¶å‡½æ•°"""
    output_img = img.copy()
    
    # é¢œè‰²æ˜ å°„
    color_map = {
        "å¿«ä¹": (0, 255, 0),     # ç»¿è‰²
        "å¹³é™": (255, 255, 0),   # é»„è‰²
        "æ‚²ä¼¤": (0, 0, 255),     # çº¢è‰²
        "æ„¤æ€’": (0, 165, 255)    # æ©™è‰²
    }
    
    for i, ((x,y,w,h), emotion) in enumerate(zip(faces, emotions)):
        color = color_map.get(emotion, (255, 255, 255))
        
        # å°†OpenCVå›¾åƒè½¬ä¸ºPILå›¾åƒ
        pil_img = Image.fromarray(cv2.cvtColor(output_img, cv2.COLOR_BGR2RGB))
        draw = ImageDraw.Draw(pil_img)
        
        try:
            # å°è¯•åŠ è½½ä¸­æ–‡å­—ä½“
            font = ImageFont.truetype("simhei.ttf", 20)
        except:
            # å›é€€åˆ°é»˜è®¤å­—ä½“
            font = ImageFont.load_default()
        
        # ç»˜åˆ¶æ–‡æœ¬èƒŒæ™¯æ¡†
        text = emotion  # ç›´æ¥ä½¿ç”¨ä¸­æ–‡æ ‡ç­¾
        text_width, text_height = draw.textsize(text, font=font)
        draw.rectangle(
            [(x, y - text_height - 10), (x + text_width + 10, y - 10)],
            fill=color,
            outline=color
        )
        
        # ç»˜åˆ¶æ–‡æœ¬
        draw.text(
            (x + 5, y - text_height - 5),
            text,
            font=font,
            fill=(255, 255, 255)  # ç™½è‰²æ–‡å­—
        
        # è½¬æ¢å›OpenCVæ ¼å¼
        output_img = cv2.cvtColor(np.array(pil_img), cv2.COLOR_RGB2BGR)
        
        # ç»˜åˆ¶äººè„¸æ¡†
        cv2.rectangle(output_img, (x,y), (x+w,y+h), color, 3)
    
    return output_img

def main():
    st.set_page_config(page_title="æƒ…ç»ªæ£€æµ‹ç³»ç»Ÿ", layout="wide")
    st.title("ğŸ˜Š æƒ…ç»ªæ£€æµ‹")
    
    uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡ï¼ˆJPG/PNGï¼‰", type=["jpg", "png"])
    
    if uploaded_file:
        try:
            # è½¬æ¢å›¾ç‰‡æ ¼å¼
            image = Image.open(uploaded_file)
            img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            
            # æ£€æµ‹æƒ…ç»ª
            emotions, faces = detect_emotion(img)
            detected_img = draw_detections(img.copy(), emotions, faces)
            
            # ä½¿ç”¨ä¸¤åˆ—å¸ƒå±€
            col1, col2 = st.columns([1, 2])
            
            with col1:
                st.subheader("æ£€æµ‹ç»“æœ")
                if emotions:
                    emotion_count = {
                        "å¿«ä¹": emotions.count("å¿«ä¹"),
                        "å¹³é™": emotions.count("å¹³é™"),
                        "æ‚²ä¼¤": emotions.count("æ‚²ä¼¤"),
                        "æ„¤æ€’": emotions.count("æ„¤æ€’")
                    }
                    
                    result = []
                    for emo, cnt in emotion_count.items():
                        if cnt > 0:
                            result.append(f"{cnt}äºº{emo}")
                    st.success("ï¼Œ".join(result))
                    
                    st.markdown("---")
                    st.markdown("**æ£€æµ‹åŸç†**ï¼š")
                    st.write("""
                    - ğŸ˜Š å¿«ä¹: æ£€æµ‹åˆ°æ˜æ˜¾ç¬‘å®¹
                    - ğŸ˜  æ„¤æ€’: çœ¼ç›çå¤§ä¸”ä½ç½®åé«˜
                    - ğŸ˜ å¹³é™: é»˜è®¤ä¸­æ€§è¡¨æƒ…
                    - ğŸ˜¢ æ‚²ä¼¤: çœ¼ç›ä½ç½®åé«˜
                    """)
                else:
                    st.warning("æœªæ£€æµ‹åˆ°äººè„¸")
            
            with col2:
                tab1, tab2 = st.tabs(["åŸå§‹å›¾ç‰‡", "åˆ†æç»“æœ"])
                with tab1:
                    st.image(image, use_container_width=True)
                with tab2:
                    st.image(detected_img, channels="BGR", use_container_width=True,
                           caption=f"æ£€æµ‹åˆ° {len(faces)} ä¸ªäººè„¸")
                
        except Exception as e:
            st.error(f"å¤„ç†é”™è¯¯: {str(e)}")

if __name__ == "__main__":
    main()
