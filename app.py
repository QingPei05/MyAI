import cv2
import numpy as np
import streamlit as st
from PIL import Image
import tempfile
from moviepy.editor import VideoFileClip

# åˆå§‹åŒ–æ£€æµ‹å™¨
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')

def detect_emotion(frame):
    """åˆ†æå•å¸§å›¾åƒçš„æƒ…ç»ªï¼ˆä»…è¿”å›æƒ…ç»ªæ ‡ç­¾ï¼‰"""
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.3, 5)
    
    emotions = []
    for (x, y, w, h) in faces:
        roi_gray = gray[y:y+h, x:x+w]
        
        # æ£€æµ‹é¢éƒ¨ç‰¹å¾
        smiles = smile_cascade.detectMultiScale(roi_gray, scaleFactor=1.8, minNeighbors=20)
        eyes = eye_cascade.detectMultiScale(roi_gray)
        
        # æƒ…ç»ªåˆ¤æ–­é€»è¾‘
        if len(smiles) > 3:
            emotions.append("excited")
        elif len(smiles) > 0:
            emotions.append("happy")
        elif len(eyes) > 0 and eyes[0][1] / h < 0.3:
            emotions.append("sad")
        else:
            emotions.append("neutral")
    
    return emotions

def process_uploaded_file(uploaded_file):
    """è‡ªåŠ¨å¤„ç†ä¸Šä¼ çš„å›¾ç‰‡æˆ–è§†é¢‘"""
    file_type = uploaded_file.type.split('/')[0]
    
    if file_type == "image":
        # å¤„ç†å›¾ç‰‡
        image = Image.open(uploaded_file)
        img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        emotions = detect_emotion(img)
        
        # ç»Ÿè®¡æƒ…ç»ª
        emotion_count = {}
        for e in emotions:
            emotion_count[e] = emotion_count.get(e, 0) + 1
        
        # æ–°å¸ƒå±€ï¼šå·¦ä¾§ç»Ÿè®¡ï¼Œå³ä¾§å›¾ç‰‡
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.subheader("æƒ…ç»ªç»Ÿè®¡")
            if emotion_count:
                result_text = "ï¼Œ".join([f"{count}äºº{emotion}" for emotion, count in emotion_count.items()])
                st.success(f"**æ£€æµ‹ç»“æœ**: {result_text}")
            else:
                st.warning("æœªæ£€æµ‹åˆ°äººè„¸")
        
        with col2:
            # å¹¶æ’æ˜¾ç¤ºåŸå›¾å’Œåˆ†æç»“æœ
            tab1, tab2 = st.tabs(["åŸå§‹å›¾ç‰‡", "åˆ†æç»“æœ"])
            with tab1:
                st.image(image, use_container_width=True)
            with tab2:
                marked_img = img.copy()
                for (x, y, w, h), emotion in zip(
                    face_cascade.detectMultiScale(cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)),
                    emotions
                ):
                    color = {
                        "happy": (0, 255, 0),      # ç»¿è‰²
                        "excited": (0, 255, 255),  # é»„è‰²
                        "sad": (0, 0, 255),        # çº¢è‰²
                        "neutral": (255, 255, 0)   # é’è‰²
                    }.get(emotion, (255, 255, 255))
                    cv2.rectangle(marked_img, (x, y), (x+w, y+h), color, 2)
                    cv2.putText(marked_img, emotion, (x, y-10),  # æ·»åŠ è‹±æ–‡æƒ…ç»ªæ ‡ç­¾
                               cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)
                st.image(marked_img, channels="BGR", use_cintainer_width=True)

def main():
    st.set_page_config(page_title="æƒ…ç»ªæ£€æµ‹ç³»ç»Ÿ", layout="centered")
    st.title("ğŸ“Š æƒ…ç»ªåˆ†ææŠ¥å‘Š")
    
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ å›¾ç‰‡æˆ–è§†é¢‘ï¼ˆJPG/PNG/MP4ï¼‰", 
        type=["jpg", "png", "jpeg", "mp4"],
        key="file_uploader"
    )
    
    if uploaded_file:
        process_uploaded_file(uploaded_file)

if __name__ == "__main__":
    main()
