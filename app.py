import cv2
import numpy as np
import streamlit as st
from PIL import Image
import tempfile
from moviepy.editor import VideoFileClip

# åˆå§‹åŒ–æ£€æµ‹å™¨
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')

def detect_emotion(frame):
    """åˆ†æå•å¸§å›¾åƒçš„æƒ…ç»ªï¼ˆä»…è¿”å›æƒ…ç»ªæ ‡ç­¾ï¼‰"""
    gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.3, 5)
    
    emotions = []
    for (x, y, w, h) in faces:
        roi_gray = gray[y:y+h, x:x+w]
        
        # æ£€æµ‹é¢éƒ¨ç‰¹å¾
        smiles = smile_cascade.detectMultiScale(roi_gray, scaleFactor=1.8, minNeighbors=20)
        eyes = eye_cascade.detectMultiScale(roi_gray)
        
        # æ‰©å±•çš„æƒ…ç»ªåˆ¤æ–­é€»è¾‘
        eye_count = len(eyes)
        smile_count = len(smiles)
        
        # çœ¼ç›ä½ç½®åˆ†æ
        eye_positions = [eye[1] for eye in eyes] if eye_count > 0 else []
        avg_eye_position = sum(eye_positions)/len(eye_positions) if eye_positions else 0
        
        # æƒ…ç»ªåˆ¤æ–­
        if smile_count > 3:
            emotions.append("å¿«ä¹")  # æ„Ÿåˆ°æ„‰å¿«ã€æ»¡è¶³å’Œå¹¸ç¦
        elif smile_count > 0:
            if eye_count > 0 and avg_eye_position < h * 0.4:
                emotions.append("å¿«ä¹")
            else:
                emotions.append("æƒŠè®¶")  # å¯¹æ„å¤–äº‹ä»¶æˆ–æƒ…å†µæ„Ÿåˆ°æ„å¤–å’ŒæƒŠå¥‡
        elif eye_count > 1:
            if avg_eye_position > h * 0.6:
                emotions.append("æ‚²ä¼¤")  # ç”±äºå¤±å»ã€å¤±æœ›æˆ–å…¶ä»–ä¸æ„‰å¿«ç»å†è€Œæ„Ÿåˆ°éš¾è¿‡å’Œæ²®ä¸§
            elif avg_eye_position < h * 0.3:
                emotions.append("æ„¤æ€’")  # ç”±äºå—åˆ°å†’çŠ¯ã€ä¸å…¬æ­£å¾…é‡æˆ–å…¶ä»–åŸå› è€Œæ„Ÿåˆ°æ¼ç«å’Œä¸æ»¡
            else:
                emotions.append("ææƒ§")  # å¯¹å±é™©æˆ–æ½œåœ¨å¨èƒæ„Ÿåˆ°å®³æ€•å’Œä¸å®‰
        else:
            emotions.append("åŒæ¶")  # å¯¹ä»¤äººä¸å¿«çš„äº‹ç‰©æ„Ÿåˆ°åæ„Ÿå’Œæ’æ–¥
    
    return emotions

def process_frame(frame):
    """å¤„ç†å•å¸§å›¾åƒå¹¶è¿”å›æ ‡è®°åçš„å›¾åƒ"""
    emotions = detect_emotion(frame)
    marked_img = frame.copy()
    
    for (x, y, w, h), emotion in zip(
        face_cascade.detectMultiScale(cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)),
        emotions
    ):
        color = {
            "å¿«ä¹": (0, 255, 0),      # ç»¿è‰²
            "æ‚²ä¼¤": (0, 0, 255),      # çº¢è‰²
            "æ„¤æ€’": (0, 0, 139),     # æ·±çº¢è‰²
            "ææƒ§": (255, 0, 0),     # è“è‰²
            "åŒæ¶": (139, 0, 139),   # ç´«è‰²
            "æƒŠè®¶": (255, 255, 0),   # é’è‰²
            "ä¸­æ€§": (255, 255, 255)  # ç™½è‰²
        }.get(emotion, (255, 255, 255))
        cv2.rectangle(marked_img, (x, y), (x+w, y+h), color, 2)
        cv2.putText(marked_img, emotion, (x, y-10),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)
    return marked_img

def process_video(video_path):
    """å¤„ç†è§†é¢‘æ–‡ä»¶"""
    cap = cv2.VideoCapture(video_path)
    stframe = st.empty()
    stop_button = st.button("åœæ­¢å¤„ç†")
    
    while cap.isOpened() and not stop_button:
        ret, frame = cap.read()
        if not ret:
            break
            
        marked_frame = process_frame(frame)
        stframe.image(marked_frame, channels="BGR")
        
    cap.release()
    if stop_button:
        st.warning("è§†é¢‘å¤„ç†å·²ä¸­æ–­")

def process_uploaded_file(uploaded_file):
    """è‡ªåŠ¨å¤„ç†ä¸Šä¼ çš„å›¾ç‰‡æˆ–è§†é¢‘"""
    file_type = uploaded_file.type.split('/')[0]
    
    if file_type == "image":
        # å¤„ç†å›¾ç‰‡
        image = Image.open(uploaded_file)
        img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
        emotions = detect_emotion(img)
        
        # ç»Ÿè®¡æƒ…ç»ª
        emotion_count = {}
        for e in emotions:
            emotion_count[e] = emotion_count.get(e, 0) + 1
        
        # æ–°å¸ƒå±€ï¼šå·¦ä¾§ç»Ÿè®¡ï¼Œå³ä¾§å›¾ç‰‡
        col1, col2 = st.columns([1, 2])
        
        with col1:
            st.subheader("æƒ…ç»ªç»Ÿè®¡")
            if emotion_count:
                # æ·»åŠ æƒ…ç»ªè¯´æ˜
                emotion_descriptions = {
                    "å¿«ä¹": "æ„Ÿåˆ°æ„‰å¿«ã€æ»¡è¶³å’Œå¹¸ç¦",
                    "æ‚²ä¼¤": "ç”±äºå¤±å»ã€å¤±æœ›æˆ–å…¶ä»–ä¸æ„‰å¿«ç»å†è€Œæ„Ÿåˆ°éš¾è¿‡å’Œæ²®ä¸§",
                    "æ„¤æ€’": "ç”±äºå—åˆ°å†’çŠ¯ã€ä¸å…¬æ­£å¾…é‡æˆ–å…¶ä»–åŸå› è€Œæ„Ÿåˆ°æ¼ç«å’Œä¸æ»¡",
                    "ææƒ§": "å¯¹å±é™©æˆ–æ½œåœ¨å¨èƒæ„Ÿåˆ°å®³æ€•å’Œä¸å®‰",
                    "åŒæ¶": "å¯¹ä»¤äººä¸å¿«çš„äº‹ç‰©æ„Ÿåˆ°åæ„Ÿå’Œæ’æ–¥",
                    "æƒŠè®¶": "å¯¹æ„å¤–äº‹ä»¶æˆ–æƒ…å†µæ„Ÿåˆ°æ„å¤–å’ŒæƒŠå¥‡"
                }
                
                result_text = "\n\n".join([
                    f"**{emotion}**: {count}äºº\n{emotion_descriptions.get(emotion, '')}"
                    for emotion, count in emotion_count.items()
                ])
                st.success(result_text)
            else:
                st.warning("æœªæ£€æµ‹åˆ°äººè„¸")
        
        with col2:
            # å¹¶æ’æ˜¾ç¤ºåŸå›¾å’Œåˆ†æç»“æœ
            tab1, tab2 = st.tabs(["åŸå§‹å›¾ç‰‡", "åˆ†æç»“æœ"])
            with tab1:
                st.image(image, use_container_width=True)
            with tab2:
                marked_img = process_frame(img)
                st.image(marked_img, channels="BGR", use_container_width=True)
    
    elif file_type == "video":
        # å¤„ç†è§†é¢‘
        with tempfile.NamedTemporaryFile(delete=False, suffix='.mp4') as tmpfile:
            tmpfile.write(uploaded_file.read())
            video_path = tmpfile.name
        
        st.info("è§†é¢‘å¤„ç†ä¸­...")
        process_video(video_path)

def main():
    st.set_page_config(page_title="æƒ…ç»ªæ£€æµ‹ç³»ç»Ÿ", layout="centered")
    st.title("ğŸ“Š æƒ…ç»ªåˆ†ææŠ¥å‘Š")
    
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ å›¾ç‰‡æˆ–è§†é¢‘ï¼ˆJPG/PNG/MP4ï¼‰", 
        type=["jpg", "png", "jpeg", "mp4"],
        key="file_uploader"
    )
    
    if uploaded_file:
        process_uploaded_file(uploaded_file)

if __name__ == "__main__":
    main()
