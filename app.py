import cv2
import numpy as np
import streamlit as st
from PIL import Image

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹ï¼ˆä½¿ç”¨æ›´å¯é çš„å‚æ•°ï¼‰
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')

def detect_emotion(img):
    """æ›´å¯é çš„æƒ…ç»ªæ£€æµ‹ï¼ˆå¿«ä¹ã€å¹³é™ã€æ‚²ä¼¤ã€æ„¤æ€’ï¼‰"""
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    # ä¼˜åŒ–çš„äººè„¸æ£€æµ‹å‚æ•°
    faces = face_cascade.detectMultiScale(
        gray,
        scaleFactor=1.05,  # æ›´ç²¾ç»†çš„ç¼©æ”¾
        minNeighbors=8,    # æ›´é«˜çš„é‚»å±…é˜ˆå€¼
        minSize=(120, 120), # æœ€å°äººè„¸å°ºå¯¸
        flags=cv2.CASCADE_SCALE_IMAGE
    )
    
    emotions = []
    valid_faces = []
    for (x,y,w,h) in faces:
        # ç¡®ä¿äººè„¸åŒºåŸŸæœ‰æ•ˆ
        if w < 50 or h < 50:  # å¿½ç•¥è¿‡å°çš„äººè„¸
            continue
            
        roi_gray = gray[y:y+h, x:x+w]
        valid_faces.append((x,y,w,h))
        
        # æ›´å¯é çš„å¾®ç¬‘æ£€æµ‹
        smiles = smile_cascade.detectMultiScale(
            roi_gray,
            scaleFactor=1.7,
            minNeighbors=22,
            minSize=(35, 35)
        )
        
        # æ›´å¯é çš„çœ¼ç›æ£€æµ‹
        eyes = eye_cascade.detectMultiScale(
            roi_gray,
            scaleFactor=1.05,
            minNeighbors=5,
            minSize=(40, 40)
        )
        
        # å¢å¼ºçš„æƒ…ç»ªåˆ¤æ–­é€»è¾‘
        emotion = "å¹³é™"  # é»˜è®¤
        
        # çœ¼ç›ç‰¹å¾åˆ†æï¼ˆç¡®ä¿æœ‰ä¸¤åªçœ¼ç›ï¼‰
        if len(eyes) >= 2:
            eye_centers = [y + ey + eh/2 for (ex,ey,ew,eh) in eyes[:2]]  # åªå–å‰ä¸¤ä¸ªçœ¼ç›
            avg_eye_height = sum(eye_centers) / len(eye_centers)
            
            # æ„¤æ€’åˆ¤æ–­ï¼ˆçœ¼ç›çå¼€ç¨‹åº¦ï¼‰
            eye_openness = sum([eh for (ex,ey,ew,eh) in eyes[:2]]) / 2
            if eye_openness > h/5 and avg_eye_height < h/2.3:
                emotion = "æ„¤æ€’"
            # æ‚²ä¼¤åˆ¤æ–­
            elif avg_eye_height > h/2.3:
                emotion = "æ‚²ä¼¤"
        
        # å¿«ä¹åˆ¤æ–­ï¼ˆä¼˜å…ˆåˆ¤æ–­ï¼‰
        if len(smiles) > 0:
            (sx,sy,sw,sh) = max(smiles, key=lambda s: s[2])  # å–æœ€å¤§ç¬‘å®¹
            if sw > w/3:  # ç¬‘å®¹å®½åº¦é˜ˆå€¼
                emotion = "å¿«ä¹"
        
        emotions.append(emotion)
    
    return emotions, valid_faces

def draw_detections(img, emotions, faces):
    """ç¡®ä¿æ ‡ç­¾æ˜¾ç¤ºçš„ç»˜åˆ¶æ–¹æ³•"""
    output_img = img.copy()
    for (x,y,w,h), emotion in zip(faces, emotions):
        # é¢œè‰²æ˜ å°„
        color_map = {
            "å¿«ä¹": (0, 200, 0),    # æ›´æŸ”å’Œçš„ç»¿è‰²
            "å¹³é™": (200, 200, 0),  # æ›´æŸ”å’Œçš„é»„è‰²
            "æ‚²ä¼¤": (0, 0, 200),    # æ›´æŸ”å’Œçš„çº¢è‰²
            "æ„¤æ€’": (0, 120, 255)   # æ›´é†’ç›®çš„æ©™è‰²
        }
        color = color_map.get(emotion, (200,200,200))
        
        # ç»˜åˆ¶å¸¦èƒŒæ™¯çš„æ–‡æœ¬ï¼ˆç¡®ä¿å¯è§æ€§ï¼‰
        text_size = cv2.getTextSize(emotion, cv2.FONT_HERSHEY_SIMPLEX, 0.8, 2)[0]
        cv2.rectangle(output_img, 
                     (x, y-35), 
                     (x + text_size[0] + 10, y-5), 
                     color, -1)  # æ–‡æœ¬èƒŒæ™¯
        cv2.putText(output_img, emotion, 
                   (x+5, y-15), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, 
                   (255,255,255), 2)  # ç™½è‰²æ–‡å­—
        
        # ç»˜åˆ¶äººè„¸æ¡†
        cv2.rectangle(output_img, (x,y), (x+w,y+h), color, 3)
    
    return output_img

def main():
    st.set_page_config(page_title="é«˜ç²¾åº¦æƒ…ç»ªæ£€æµ‹", layout="wide")
    st.title("ğŸ˜Š é«˜ç²¾åº¦æƒ…ç»ªæ£€æµ‹")
    
    uploaded_file = st.file_uploader("ä¸Šä¼ æ¸…æ™°æ­£è„¸ç…§ç‰‡ï¼ˆJPG/PNGï¼‰", type=["jpg", "png"])
    
    if uploaded_file:
        try:
            # è½¬æ¢å›¾ç‰‡æ ¼å¼
            image = Image.open(uploaded_file)
            img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            
            # æ£€æµ‹æƒ…ç»ª
            emotions, faces = detect_emotion(img)
            detected_img = draw_detections(img.copy(), emotions, faces)
            
            # ä½¿ç”¨ä¸¤åˆ—å¸ƒå±€
            col1, col2 = st.columns([1, 2])
            
            with col1:
                st.subheader("æ£€æµ‹ç»“æœ")
                if emotions:
                    emotion_count = {
                        "å¿«ä¹": emotions.count("å¿«ä¹"),
                        "å¹³é™": emotions.count("å¹³é™"),
                        "æ‚²ä¼¤": emotions.count("æ‚²ä¼¤"),
                        "æ„¤æ€’": emotions.count("æ„¤æ€’")
                    }
                    
                    result = []
                    for emo, cnt in emotion_count.items():
                        if cnt > 0:
                            result.append(f"{cnt}äºº{emo}")
                    st.success("ï¼Œ".join(result))
                    
                    st.markdown("---")
                    st.markdown("**ä¼˜åŒ–è¯´æ˜**ï¼š")
                    st.write("""
                    - é‡‡ç”¨æ›´ä¸¥æ ¼çš„äººè„¸æ£€æµ‹å‚æ•°
                    - æƒ…ç»ªæ ‡ç­¾ç°åœ¨å¸¦æœ‰èƒŒæ™¯æ¡†
                    - ä¼˜åŒ–äº†æ„¤æ€’å’Œæ‚²ä¼¤çš„åˆ¤æ–­é€»è¾‘
                    """)
                else:
                    st.warning("æœªæ£€æµ‹åˆ°æœ‰æ•ˆäººè„¸ï¼Œè¯·ä¸Šä¼ æ›´æ¸…æ™°çš„æ­£è„¸ç…§ç‰‡")
            
            with col2:
                # å›¾ç‰‡æ˜¾ç¤º
                tab1, tab2 = st.tabs(["åŸå§‹å›¾ç‰‡", "åˆ†æç»“æœ"])
                with tab1:
                    st.image(image, use_container_width=True, caption="ä¸Šä¼ çš„åŸå§‹å›¾ç‰‡")
                with tab2:
                    st.image(detected_img, channels="BGR", use_container_width=True, 
                           caption=f"æ£€æµ‹åˆ° {len(faces)} ä¸ªäººè„¸")
                
        except Exception as e:
            st.error(f"å›¾ç‰‡å¤„ç†å¤±è´¥: {str(e)}")
            st.info("è¯·å°è¯•ä¸Šä¼ ä¸åŒè§’åº¦æˆ–æ›´æ¸…æ™°çš„ç…§ç‰‡")

if __name__ == "__main__":
    main()
