import cv2
import numpy as np
import streamlit as st
from PIL import Image

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')

def detect_emotion(img):
    """ä½¿ç”¨OpenCVæ£€æµ‹æƒ…ç»ªï¼ˆhappy/neutral/sadï¼‰"""
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.3, 5)
    
    emotions = []
    for (x,y,w,h) in faces:
        roi_gray = gray[y:y+h, x:x+w]
        
        # æ£€æµ‹å¾®ç¬‘
        smiles = smile_cascade.detectMultiScale(roi_gray, scaleFactor=1.8, minNeighbors=20)
        # æ£€æµ‹çœ¼ç›
        eyes = eye_cascade.detectMultiScale(roi_gray)
        
        # æƒ…ç»ªåˆ¤æ–­é€»è¾‘
        emotion = "neutral"  # é»˜è®¤
        if len(smiles) > 0:
            emotion = "happy"
        elif len(eyes) > 0:
            if eyes[0][1] < h/3:  # çœ¼ç›ä½ç½®åé«˜
                emotion = "sad"
        
        emotions.append(emotion)
    
    return emotions, faces

def draw_detections(img, emotions, faces):
    """åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ"""
    for (x,y,w,h), emotion in zip(faces, emotions):
        # äººè„¸æ¡†é¢œè‰²æ ¹æ®æƒ…ç»ªå˜åŒ–
        color = {
            "happy": (0, 255, 0),    # ç»¿è‰²
            "neutral": (255, 255, 0), # é»„è‰²
            "sad": (0, 0, 255)       # çº¢è‰²
        }.get(emotion, (255,255,255))
        
        cv2.rectangle(img, (x,y), (x+w,y+h), color, 2)
        cv2.putText(img, emotion, (x, y-10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.9, color, 2)
    
    return img

def main():
    st.set_page_config(page_title="æƒ…ç»ªæ£€æµ‹ç³»ç»Ÿ", layout="wide")
    st.title("ğŸ˜Š æƒ…ç»ªæ£€æµ‹")
    
    uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡ï¼ˆJPG/PNGï¼‰", type=["jpg", "png"])
    
    if uploaded_file:
        try:
            # è½¬æ¢å›¾ç‰‡æ ¼å¼
            image = Image.open(uploaded_file)
            img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            
            # æ£€æµ‹æƒ…ç»ª
            emotions, faces = detect_emotion(img)
            detected_img = draw_detections(img.copy(), emotions, faces)
            
            # æ˜¾ç¤ºç»“æœ
            col1, col2 = st.columns(2)
            with col1:
                st.image(image, caption="åŸå§‹å›¾ç‰‡", use_container_width=True)
            with col2:
                st.image(detected_img, channels="BGR", caption="åˆ†æç»“æœ", use_container_width=True)
            
            # æƒ…ç»ªç»Ÿè®¡è¾“å‡º
            st.subheader("æ£€æµ‹ç»“æœ")
            if emotions:
                # ç»Ÿè®¡æ¯ç§æƒ…ç»ªçš„äººæ•°
                emotion_count = {
                    "happy": emotions.count("happy"),
                    "neutral": emotions.count("neutral"),
                    "sad": emotions.count("sad")
                }
                
                # ç”Ÿæˆç®€æ´çš„è¾“å‡ºæ–‡æœ¬
                result_parts = []
                if emotion_count["happy"] > 0:
                    result_parts.append(f"{emotion_count['happy']}äººå¼€å¿ƒ")
                if emotion_count["neutral"] > 0:
                    result_parts.append(f"{emotion_count['neutral']}äººå¹³é™")
                if emotion_count["sad"] > 0:
                    result_parts.append(f"{emotion_count['sad']}äººä¼¤å¿ƒ")
                
                st.success("ï¼Œ".join(result_parts))
            else:
                st.warning("æœªæ£€æµ‹åˆ°äººè„¸")
                
        except Exception as e:
            st.error(f"å¤„ç†é”™è¯¯: {str(e)}")

if __name__ == "__main__":
    main()
