import cv2
import numpy as np
import streamlit as st
from PIL import Image

# åŠ è½½é¢„è®­ç»ƒæ¨¡å‹
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
eye_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_eye.xml')
smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')

def detect_emotion(img):
    """å¢å¼ºç‰ˆæƒ…ç»ªæ£€æµ‹ï¼ˆ9ç§æƒ…ç»ªï¼‰"""
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.3, 5)
    
    emotions = []
    for (x,y,w,h) in faces:
        roi_gray = gray[y:y+h, x:x+w]
        roi_color = img[y:y+h, x:x+w]
        
        # æ£€æµ‹é¢éƒ¨ç‰¹å¾
        smiles = smile_cascade.detectMultiScale(roi_gray, scaleFactor=1.8, minNeighbors=20)
        eyes = eye_cascade.detectMultiScale(roi_gray, scaleFactor=1.1, minNeighbors=5)
        
        # å¢å¼ºçš„æƒ…ç»ªåˆ¤æ–­é€»è¾‘
        emotion = "å¹³é™"  # é»˜è®¤
        
        # çœ¼ç›ç‰¹å¾åˆ†æ
        eye_features = []
        if len(eyes) >= 2:  # æ£€æµ‹åˆ°ä¸¤åªçœ¼ç›
            eye1 = eyes[0]
            eye2 = eyes[1]
            eye_center_y = (eye1[1] + eye2[1]) / 2
            eye_openness = (eye1[3] + eye2[3]) / 2  # çœ¼ç›é«˜åº¦
            
            # æ„¤æ€’/æƒŠè®¶åˆ¤æ–­
            if eye_openness > h/6:
                emotion = "æ„¤æ€’" if eye_center_y < h/3 else "æƒŠè®¶"
            # æ‚²ä¼¤åˆ¤æ–­
            elif eye_center_y > h/2.5:
                emotion = "æ‚²ä¼¤"
        
        # å˜´å·´ç‰¹å¾åˆ†æ
        if len(smiles) > 0:
            (sx,sy,sw,sh) = smiles[0]
            smile_ratio = sw / w  # ç¬‘å®¹å®½åº¦ä¸è„¸å®½æ¯”ä¾‹
            
            if smile_ratio > 0.4:
                emotion = "å¿«ä¹"
            elif smile_ratio > 0.25:
                emotion = "éª„å‚²" if eye_openness < h/8 else "å¿«ä¹"
        
        # ç‰¹æ®Šæƒ…ç»ªåˆ¤æ–­
        if len(eyes) == 1:  # å•çœ¼å¯è§å¯èƒ½æ˜¯åŒæ¶
            emotion = "åŒæ¶"
        elif len(eyes) > 2:  # å¤šçœ¼æ£€æµ‹å¯èƒ½æ˜¯ææƒ§
            emotion = "ææƒ§"
        
        # æ ¹æ®é¢éƒ¨ä½ç½®è°ƒæ•´ï¼ˆç¾¡æ…•é€šå¸¸æœ‰è½»å¾®æŠ¬å¤´ï¼‰
        if y < img.shape[0]/4 and emotion == "å¹³é™":
            emotion = "ç¾¡æ…•"
        
        emotions.append(emotion)
    
    return emotions, faces

def draw_detections(img, emotions, faces):
    """åœ¨å›¾åƒä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœï¼ˆ9ç§æƒ…ç»ªé¢œè‰²æ ‡è®°ï¼‰"""
    for (x,y,w,h), emotion in zip(faces, emotions):
        # 9ç§æƒ…ç»ªçš„é¢œè‰²æ˜ å°„
        color_map = {
            "å¿«ä¹": (0, 255, 0),      # ç»¿è‰²
            "å¹³é™": (255, 255, 0),    # é»„è‰²
            "æ‚²ä¼¤": (0, 0, 255),      # çº¢è‰²
            "æ„¤æ€’": (0, 165, 255),    # æ©™è‰²
            "æƒŠè®¶": (255, 0, 255),    # ç²‰è‰²
            "ææƒ§": (128, 0, 128),    # ç´«è‰²
            "åŒæ¶": (0, 128, 0),      # æ·±ç»¿è‰²
            "éª„å‚²": (255, 215, 0),    # é‡‘è‰²
            "ç¾¡æ…•": (64, 224, 208)    # é’ç»¿è‰²
        }
        color = color_map.get(emotion, (255,255,255))
        
        # ç»˜åˆ¶äººè„¸æ¡†å’Œæ ‡ç­¾
        cv2.rectangle(img, (x,y), (x+w,y+h), color, 3)
        cv2.putText(img, emotion, (x, y-15), 
                   cv2.FONT_HERSHEY_SIMPLEX, 0.8, color, 3)
    
    return img

def main():
    st.set_page_config(page_title="é«˜çº§æƒ…ç»ªæ£€æµ‹ç³»ç»Ÿ", layout="wide")
    st.title("ğŸ˜ŠğŸ˜¢ğŸ˜  é«˜çº§æƒ…ç»ªæ£€æµ‹")
    
    uploaded_file = st.file_uploader("ä¸Šä¼ å›¾ç‰‡ï¼ˆJPG/PNGï¼‰", type=["jpg", "png"])
    
    if uploaded_file:
        try:
            # è½¬æ¢å›¾ç‰‡æ ¼å¼
            image = Image.open(uploaded_file)
            img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            
            # æ£€æµ‹æƒ…ç»ª
            emotions, faces = detect_emotion(img)
            detected_img = draw_detections(img.copy(), emotions, faces)
            
            # ä½¿ç”¨ä¸¤åˆ—å¸ƒå±€
            col1, col2 = st.columns([1, 2])
            
            with col1:
                # æƒ…ç»ªç»Ÿè®¡ç»“æœ
                st.subheader("æ£€æµ‹ç»“æœ")
                if emotions:
                    emotion_count = {e: emotions.count(e) for e in set(emotions)}
                    
                    # æŒ‰æƒ…ç»ªç±»å‹æ’åºè¾“å‡º
                    emotion_order = ["å¿«ä¹", "å¹³é™", "æ‚²ä¼¤", "æ„¤æ€’", 
                                    "æƒŠè®¶", "ææƒ§", "åŒæ¶", "éª„å‚²", "ç¾¡æ…•"]
                    result_parts = []
                    for e in emotion_order:
                        if e in emotion_count and emotion_count[e] > 0:
                            result_parts.append(f"{emotion_count[e]}äºº{e}")
                    
                    st.success("ï¼Œ".join(result_parts))
                    
                    # æƒ…ç»ªè¯´æ˜
                    st.markdown("---")
                    st.markdown("**æƒ…ç»ªè¯´æ˜**")
                    st.write("""
                    - ğŸ˜Š å¿«ä¹: æ˜æ˜¾ç¬‘å®¹
                    - ğŸ˜ å¹³é™: ä¸­æ€§è¡¨æƒ…
                    - ğŸ˜¢ æ‚²ä¼¤: çœ¼ç›ä¸‹å‚
                    - ğŸ˜  æ„¤æ€’: çªå¤§çœ¼ç›
                    - ğŸ˜² æƒŠè®¶: çœ¼ç›çå¤§
                    - ğŸ˜¨ ææƒ§: çœ¼ç›ç´§å¼ 
                    - ğŸ¤¢ åŒæ¶: å•çœ¼å¾®é—­
                    - ğŸ¦š éª„å‚²: è½»å¾®å¾®ç¬‘
                    - ğŸ˜ ç¾¡æ…•: è½»å¾®æŠ¬å¤´
                    """)
                else:
                    st.warning("æœªæ£€æµ‹åˆ°äººè„¸")
            
            with col2:
                # å›¾ç‰‡æ˜¾ç¤º
                tab1, tab2 = st.tabs(["åŸå§‹å›¾ç‰‡", "åˆ†æç»“æœ"])
                with tab1:
                    st.image(image, use_container_width=True)
                with tab2:
                    st.image(detected_img, channels="BGR", use_container_width=True)
                
        except Exception as e:
            st.error(f"å¤„ç†é”™è¯¯: {str(e)}")

if __name__ == "__main__":
    main()
