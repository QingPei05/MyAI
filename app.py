def detect_emotion(img):
    """ä½¿ç”¨OpenCVæ£€æµ‹æƒ…ç»ªï¼ˆè¿”å›è‹±æ–‡æ ‡ç­¾ï¼‰"""
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, 1.3, 5)
    
    emotions = []
    for (x,y,w,h) in faces:
        roi_gray = gray[y:y+h, x:x+w]
        
        # æ£€æµ‹å¾®ç¬‘
        smiles = smile_cascade.detectMultiScale(roi_gray, scaleFactor=1.8, minNeighbors=20)
        # æ£€æµ‹çœ¼ç›
        eyes = eye_cascade.detectMultiScale(roi_gray)
        
        # æƒ…ç»ªåˆ¤æ–­é€»è¾‘ï¼ˆè‹±æ–‡æ ‡ç­¾ï¼‰
        emotion = "neutral"  # é»˜è®¤
        
        # æ„¤æ€’åˆ¤æ–­
        if len(eyes) >= 2:
            eye_centers = [y + ey + eh/2 for (ex,ey,ew,eh) in eyes[:2]]
            avg_eye_height = np.mean(eye_centers)
            eye_sizes = [eh for (ex,ey,ew,eh) in eyes[:2]]
            avg_eye_size = np.mean(eye_sizes)
            
            if avg_eye_size > h/5 and avg_eye_height < h/2.5:
                emotion = "angry"
            elif avg_eye_height < h/3:
                emotion = "sad"
        
        # å¿«ä¹åˆ¤æ–­
        if len(smiles) > 0:
            emotion = "happy"
        
        emotions.append(emotion)
    
    return emotions, faces

def draw_detections(img, emotions, faces):
    """ç»˜åˆ¶è‹±æ–‡æ ‡ç­¾"""
    output_img = img.copy()
    
    # é¢œè‰²æ˜ å°„
    color_map = {
        "happy": (0, 255, 0),    # ç»¿è‰²
        "neutral": (255, 255, 0), # é»„è‰²
        "sad": (0, 0, 255),      # çº¢è‰²
        "angry": (0, 165, 255)    # æ©™è‰²
    }
    
    for i, ((x,y,w,h), emotion) in enumerate(zip(faces, emotions)):
        color = color_map.get(emotion, (255, 255, 255))
        
        # ç»˜åˆ¶äººè„¸æ¡†
        cv2.rectangle(output_img, (x,y), (x+w,y+h), color, 3)
        
        # æ·»åŠ è‹±æ–‡æ ‡ç­¾
        cv2.putText(output_img, 
                   emotion.upper(), 
                   (x+5, y-10), 
                   cv2.FONT_HERSHEY_SIMPLEX, 
                   0.8, 
                   color, 
                   2)
    
    return output_img

def main():
    st.set_page_config(page_title="Emotion Detection", layout="wide")
    st.title("ğŸ˜Š Emotion Detection")
    
    uploaded_file = st.file_uploader("Upload Image (JPG/PNG)", type=["jpg", "png"])
    
    if uploaded_file:
        try:
            # è½¬æ¢å›¾ç‰‡æ ¼å¼
            image = Image.open(uploaded_file)
            img = cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)
            
            # æ£€æµ‹æƒ…ç»ª
            emotions, faces = detect_emotion(img)
            detected_img = draw_detections(img.copy(), emotions, faces)
            
            # ä½¿ç”¨ä¸¤åˆ—å¸ƒå±€
            col1, col2 = st.columns([1, 2])
            
            with col1:
                st.subheader("Detection Results")
                if emotions:
                    emotion_count = {
                        "Happy": emotions.count("happy"),
                        "Neutral": emotions.count("neutral"),
                        "Sad": emotions.count("sad"),
                        "Angry": emotions.count("angry")
                    }
                    
                    result = []
                    for emo, cnt in emotion_count.items():
                        if cnt > 0:
                            result.append(f"{cnt} {emo}")
                    st.success(", ".join(result))
                    
                    st.markdown("---")
                    st.markdown("**Detection Logic**:")
                    st.write("""
                    - ğŸ˜Š Happy: Detected smile
                    - ğŸ˜  Angry: Wide open eyes in upper face
                    - ğŸ˜ Neutral: Default expression
                    - ğŸ˜¢ Sad: Eyes positioned higher
                    """)
                else:
                    st.warning("No faces detected")
            
            with col2:
                tab1, tab2 = st.tabs(["Original", "Analysis"])
                with tab1:
                    st.image(image, use_column_width=True)
                with tab2:
                    st.image(detected_img, channels="BGR", use_column_width=True,
                           caption=f"Detected {len(faces)} faces")
                
        except Exception as e:
            st.error(f"Processing error: {str(e)}")
