import cv2
import numpy as np
import streamlit as st
from PIL import Image
import tempfile
import os
from moviepy.editor import VideoFileClip

# åˆå§‹åŒ–æ£€æµ‹å™¨ï¼ˆå¿«é€Ÿå‚æ•°ï¼‰
face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_frontalface_default.xml')
smile_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + 'haarcascade_smile.xml')

# ä¼šè¯çŠ¶æ€å­˜å‚¨
if 'uploaded_files' not in st.session_state:
    st.session_state.uploaded_files = []

def detect_emotion_fast(img):
    """æé€Ÿæƒ…ç»ªæ£€æµ‹"""
    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)
    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.2, minNeighbors=5)
    
    emotions = []
    for (x,y,w,h) in faces:
        roi_gray = gray[y:y+h, x:x+w]
        smiles = smile_cascade.detectMultiScale(roi_gray, scaleFactor=1.7, minNeighbors=15)
        
        if len(smiles) > 3:
            emotions.append("å…´å¥‹")
        elif len(smiles) > 0:
            emotions.append("å¼€å¿ƒ")
        else:
            emotions.append("éš¾å—")
    
    return emotions

def process_media(file):
    """è‡ªåŠ¨å¤„ç†å›¾ç‰‡/è§†é¢‘"""
    file_type = file.type.split('/')[0]
    temp_path = None
    
    try:
        if file_type == "image":
            # å¤„ç†å›¾ç‰‡
            img = Image.open(file)
            cv_img = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)
            emotions = detect_emotion_fast(cv_img)
            
            # å­˜å‚¨ç»“æœ
            st.session_state.uploaded_files.append({
                "name": file.name,
                "type": "image",
                "emotions": emotions,
                "data": img,
                "temp_path": None
            })
            
        elif file_type == "video":
            # ä¿å­˜ä¸´æ—¶è§†é¢‘æ–‡ä»¶
            with tempfile.NamedTemporaryFile(delete=False, suffix=".mp4") as tmp:
                tmp.write(file.read())
                temp_path = tmp.name
            
            # å¿«é€Ÿåˆ†æå‰10ç§’
            clip = VideoFileClip(temp_path).subclip(0, min(10, VideoFileClip(temp_path).duration))
            emotions = []
            for frame in clip.iter_frames(fps=5):  # é™å¸§åˆ†æ
                frame = cv2.resize(frame, (640, 360))
                emotions.extend(detect_emotion_fast(frame))
            
            # ç»Ÿè®¡æƒ…ç»ª
            emotion_count = {}
            for e in emotions:
                emotion_count[e] = emotion_count.get(e, 0) + 1
            
            st.session_state.uploaded_files.append({
                "name": file.name,
                "type": "video",
                "emotions": emotion_count,
                "data": temp_path,
                "temp_path": temp_path
            })
    
    except Exception as e:
        st.error(f"å¤„ç†å¤±è´¥: {str(e)}")
        if temp_path and os.path.exists(temp_path):
            os.unlink(temp_path)

def delete_file(index):
    """åˆ é™¤æŒ‡å®šæ–‡ä»¶"""
    if st.session_state.uploaded_files[index]["temp_path"] and os.path.exists(st.session_state.uploaded_files[index]["temp_path"]):
        os.unlink(st.session_state.uploaded_files[index]["temp_path"])
    st.session_state.uploaded_files.pop(index)
    st.rerun()

def main():
    st.set_page_config(page_title="æé€Ÿæƒ…ç»ªæ£€æµ‹", layout="centered")
    st.title("ğŸ“¸âš¡ åª’ä½“æƒ…ç»ªå¿«æ£€")
    
    # æ–‡ä»¶ä¸Šä¼ åŒº
    uploaded_file = st.file_uploader(
        "ä¸Šä¼ å›¾ç‰‡æˆ–è§†é¢‘ï¼ˆJPG/PNG/MP4ï¼‰",
        type=["jpg", "png", "jpeg", "mp4"],
        accept_multiple_files=False,
        key="file_uploader"
    )
    
    if uploaded_file and uploaded_file not in [f["name"] for f in st.session_state.uploaded_files]:
        process_media(uploaded_file)
        st.rerun()
    
    # ç»“æœæ˜¾ç¤ºåŒº
    for i, file in enumerate(st.session_state.uploaded_files):
        with st.container(border=True):
            col1, col2 = st.columns([0.9, 0.1])
            with col1:
                st.subheader(f"ğŸ“Œ {file['name']}")
                
                if file["type"] == "image":
                    # å›¾ç‰‡æ˜¾ç¤º
                    st.image(file["data"], caption="ä¸Šä¼ å›¾ç‰‡")
                    emotions_text = "ï¼Œ".join(file["emotions"]) if file["emotions"] else "æœªæ£€æµ‹åˆ°äººè„¸"
                    st.markdown(f"**æƒ…ç»ªåˆ†æ**: {emotions_text}")
                
                else:
                    # è§†é¢‘æ˜¾ç¤º
                    st.video(file["data"])
                    emotions_text = "ï¼Œ".join([f"{count}äºº{emotion}" for emotion, count in file["emotions"].items()])
                    st.markdown(f"**æƒ…ç»ªç»Ÿè®¡**: {emotions_text}")
            
            with col2:
                # åˆ é™¤æŒ‰é’®
                st.button("ğŸ—‘ï¸", key=f"del_{i}", on_click=delete_file, args=(i,), 
                         help="åˆ é™¤æ­¤æ–‡ä»¶")

if __name__ == "__main__":
    main()
